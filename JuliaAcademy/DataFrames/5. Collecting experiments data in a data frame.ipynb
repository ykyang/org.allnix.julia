{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting experiments data in a data frame\n",
    "\n",
    "### Bogumił Kamiński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will run a simple Monte Carlo simulation so show examples how one can work with data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following puzzle.\n",
    "\n",
    "We draw independent random numbers from $U(0,1)$ distribution. On the average, how many draws do we need, till the sum of these numbers exceeds $1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code that runs this experiment once. For tutorial reasons we keep all the generated random numbers and recalculate their sum in each iteration (you can try to improve the efficiency of this code as an exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_e (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sim_e()\n",
    "    draw = Float64[]\n",
    "    while true\n",
    "        push!(draw, rand())\n",
    "        sum(draw) > 1.0 && return draw\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234); # just to make sure we get the same results if we are on the same version of Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run our simulation several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float64}}:\n",
       " [0.5908446386657102, 0.7667970365022592]\n",
       " [0.5662374165061859, 0.4600853424625171]\n",
       " [0.7940257103317943, 0.8541465903790502]\n",
       " [0.20058603493384108, 0.2986142783434118, 0.24683718661000897, 0.5796722333690416]\n",
       " [0.6488819502093455, 0.010905889635595356, 0.06642303695533736, 0.9567533636029237]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [sim_e() for _ in 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check that each time we finished just when we exceeded $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 1.3576416751679694\n",
       " 1.026322758968703\n",
       " 1.6481723007108444\n",
       " 1.3257097332563035\n",
       " 1.682964240403202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum.(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.5908446386657102\n",
       " 0.5662374165061859\n",
       " 0.7940257103317943\n",
       " 0.7460374998872619\n",
       " 0.7262108768002782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@. sum(res) - last(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All looks good so far! (and as a bonus we have just made a small exercise in broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us populate a data frame with the results of our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.792677 seconds (151.89 M allocations: 4.928 GiB, 29.78% gc time, 7.13% compilation time)\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame()\n",
    "\n",
    "@time for i in 1:10^7\n",
    "    push!(df, (id=i, pos=sim_e()))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the process was quite fast, `push!`-ing data to a `DataFrame` is efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th></tr><tr><th></th><th>Int64</th><th>Array…</th></tr></thead><tbody><p>10,000,000 rows × 2 columns</p><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& id & pos\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array…\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×2 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\n",
       "──────────┼─────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]\n",
       "        3 │        3  [0.950498, 0.96467]\n",
       "        4 │        4  [0.945775, 0.789904]\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …\n",
       "        8 │        8  [0.732, 0.299058]\n",
       "        9 │        9  [0.449182, 0.875096]\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…\n",
       "    ⋮     │    ⋮                      ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]\n",
       "  9999992 │  9999992  [0.231368, 0.862016]\n",
       "  9999993 │  9999993  [0.869351, 0.444795]\n",
       "  9999994 │  9999994  [0.821356, 0.509054]\n",
       "  9999995 │  9999995  [0.589245, 0.669708]\n",
       "  9999996 │  9999996  [0.806262, 0.734397]\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]\n",
       "\u001b[36m                                    9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us count the number of jumps we have made in each step using the `transform!` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th><th>jumps</th></tr><tr><th></th><th>Int64</th><th>Array…</th><th>Int64</th></tr></thead><tbody><p>10,000,000 rows × 3 columns</p><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td><td>3</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td><td>3</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td><td>2</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td><td>2</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td><td>4</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td><td>3</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td><td>5</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td><td>2</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td><td>2</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td><td>3</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td><td>5</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td><td>3</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td><td>3</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td><td>3</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td><td>2</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td><td>3</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td><td>2</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td><td>4</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td><td>4</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td><td>3</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td><td>3</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td><td>3</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td><td>3</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td><td>3</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td><td>3</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td><td>3</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td><td>2</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td><td>4</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td><td>3</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td><td>2</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & pos & jumps\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array… & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] & 3 \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] & 3 \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] & 2 \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] & 2 \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] & 4 \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] & 3 \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] & 5 \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] & 2 \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] & 2 \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] & 3 \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] & 5 \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] & 3 \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] & 3 \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] & 3 \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] & 2 \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] & 3 \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] & 2 \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] & 4 \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] & 4 \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] & 3 \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] & 3 \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] & 3 \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] & 3 \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] & 3 \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] & 3 \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] & 3 \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] & 2 \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] & 4 \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] & 3 \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] & 2 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×3 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\u001b[1m jumps \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────────┼────────────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]         3\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]        3\n",
       "        3 │        3  [0.950498, 0.96467]                    2\n",
       "        4 │        4  [0.945775, 0.789904]                   2\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …      4\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]          3\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …      5\n",
       "        8 │        8  [0.732, 0.299058]                      2\n",
       "        9 │        9  [0.449182, 0.875096]                   2\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]        3\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…      5\n",
       "    ⋮     │    ⋮                      ⋮                    ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]         3\n",
       "  9999992 │  9999992  [0.231368, 0.862016]                   2\n",
       "  9999993 │  9999993  [0.869351, 0.444795]                   2\n",
       "  9999994 │  9999994  [0.821356, 0.509054]                   2\n",
       "  9999995 │  9999995  [0.589245, 0.669708]                   2\n",
       "  9999996 │  9999996  [0.806262, 0.734397]                   2\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…      4\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]        3\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]          3\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]                   2\n",
       "\u001b[36m                                           9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform!(df, :pos => ByRow(length) => :jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us dissect what we have written above:\n",
    "* `transform!` adds columns to a data frame in-place\n",
    "* `:pos` is a source column\n",
    "* `ByRow(length)` tells us that we want to apply `length` function to each element for `:pos` column (without it `length` would be applied to the whole column - can you guess what would be the result?)\n",
    "* `:jumps` is the name of the column that should be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to find the average number of jumps that are made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7185991"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(df.jumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>jumps_mean</th></tr><tr><th></th><th>Float64</th></tr></thead><tbody><p>1 rows × 1 columns</p><tr><th>1</th><td>2.7186</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& jumps\\_mean\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.7186 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1×1 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps_mean \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64    \u001b[0m\n",
       "─────┼────────────\n",
       "   1 │     2.7186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine(df, :jumps => mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which happens to be very close to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ℯ = 2.7182818284590..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MathConstants.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now find a distribution of number of jumps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>jumps</th><th>jumps_length</th></tr><tr><th></th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>2</td><td>4999743</td></tr><tr><th>2</th><td>3</td><td>3332539</td></tr><tr><th>3</th><td>4</td><td>1250009</td></tr><tr><th>4</th><td>5</td><td>333738</td></tr><tr><th>5</th><td>6</td><td>69865</td></tr><tr><th>6</th><td>7</td><td>12145</td></tr><tr><th>7</th><td>8</td><td>1725</td></tr><tr><th>8</th><td>9</td><td>204</td></tr><tr><th>9</th><td>10</td><td>31</td></tr><tr><th>10</th><td>11</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& jumps & jumps\\_length\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 4999743 \\\\\n",
       "\t2 & 3 & 3332539 \\\\\n",
       "\t3 & 4 & 1250009 \\\\\n",
       "\t4 & 5 & 333738 \\\\\n",
       "\t5 & 6 & 69865 \\\\\n",
       "\t6 & 7 & 12145 \\\\\n",
       "\t7 & 8 & 1725 \\\\\n",
       "\t8 & 9 & 204 \\\\\n",
       "\t9 & 10 & 31 \\\\\n",
       "\t10 & 11 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps \u001b[0m\u001b[1m jumps_length \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64        \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │     2       4999743\n",
       "   2 │     3       3332539\n",
       "   3 │     4       1250009\n",
       "   4 │     5        333738\n",
       "   5 │     6         69865\n",
       "   6 │     7         12145\n",
       "   7 │     8          1725\n",
       "   8 │     9           204\n",
       "   9 │    10            31\n",
       "  10 │    11             1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumps_agg = @pipe df |>\n",
    "                  groupby(_, :jumps, sort=true) |>\n",
    "                  combine(_, :jumps => length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and normalize it as a fraction (and at the same time calculate some theoretical result that we have *guessed* :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>jumps</th><th>jumps_length</th><th>simulation</th><th>theory</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10 rows × 4 columns</p><tr><th>1</th><td>2</td><td>4999743</td><td>0.499974</td><td>0.5</td></tr><tr><th>2</th><td>3</td><td>3332539</td><td>0.333254</td><td>0.333333</td></tr><tr><th>3</th><td>4</td><td>1250009</td><td>0.125001</td><td>0.125</td></tr><tr><th>4</th><td>5</td><td>333738</td><td>0.0333738</td><td>0.0333333</td></tr><tr><th>5</th><td>6</td><td>69865</td><td>0.0069865</td><td>0.00694444</td></tr><tr><th>6</th><td>7</td><td>12145</td><td>0.0012145</td><td>0.00119048</td></tr><tr><th>7</th><td>8</td><td>1725</td><td>0.0001725</td><td>0.000173611</td></tr><tr><th>8</th><td>9</td><td>204</td><td>2.04e-5</td><td>2.20459e-5</td></tr><tr><th>9</th><td>10</td><td>31</td><td>3.1e-6</td><td>2.48016e-6</td></tr><tr><th>10</th><td>11</td><td>1</td><td>1.0e-7</td><td>2.50521e-7</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& jumps & jumps\\_length & simulation & theory\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2 & 4999743 & 0.499974 & 0.5 \\\\\n",
       "\t2 & 3 & 3332539 & 0.333254 & 0.333333 \\\\\n",
       "\t3 & 4 & 1250009 & 0.125001 & 0.125 \\\\\n",
       "\t4 & 5 & 333738 & 0.0333738 & 0.0333333 \\\\\n",
       "\t5 & 6 & 69865 & 0.0069865 & 0.00694444 \\\\\n",
       "\t6 & 7 & 12145 & 0.0012145 & 0.00119048 \\\\\n",
       "\t7 & 8 & 1725 & 0.0001725 & 0.000173611 \\\\\n",
       "\t8 & 9 & 204 & 2.04e-5 & 2.20459e-5 \\\\\n",
       "\t9 & 10 & 31 & 3.1e-6 & 2.48016e-6 \\\\\n",
       "\t10 & 11 & 1 & 1.0e-7 & 2.50521e-7 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m jumps \u001b[0m\u001b[1m jumps_length \u001b[0m\u001b[1m simulation \u001b[0m\u001b[1m theory      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "─────┼──────────────────────────────────────────────\n",
       "   1 │     2       4999743   0.499974   0.5\n",
       "   2 │     3       3332539   0.333254   0.333333\n",
       "   3 │     4       1250009   0.125001   0.125\n",
       "   4 │     5        333738   0.0333738  0.0333333\n",
       "   5 │     6         69865   0.0069865  0.00694444\n",
       "   6 │     7         12145   0.0012145  0.00119048\n",
       "   7 │     8          1725   0.0001725  0.000173611\n",
       "   8 │     9           204   2.04e-5    2.20459e-5\n",
       "   9 │    10            31   3.1e-6     2.48016e-6\n",
       "  10 │    11             1   1.0e-7     2.50521e-7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform!(jumps_agg,\n",
    "           :jumps_length => (x -> x ./ sum(x)) => :simulation,\n",
    "           :jumps => ByRow(x -> (x-1) / factorial(x)) => :theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly justify how we have guessed it (you can safely skip the derivation):\n",
    "\n",
    "Formula\n",
    "$$\n",
    "p_n = \\frac{n-1}{n!}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{n=2}^{+\\infty}p_n=\\sum_{n=2}^{+\\infty} \\frac{n-1}{n!} = \\sum_{n=1}^{+\\infty} \\frac{1}{n!} - \\sum_{n=2}^{+\\infty} \\frac{1}{n!} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{n=2}^{+\\infty}n\\cdot p_n=\\sum_{n=2}^{+\\infty} n\\frac{n-1}{n!} = \\sum_{n=2}^{+\\infty} \\frac{1}{(n-2)!} = e\n",
    "$$\n",
    "\n",
    "Now we note that:\n",
    "\n",
    "$$\n",
    "1-\\sum_{n=2}^k p_n = \\frac{1}{k!}\n",
    "$$\n",
    "which can be most easily justified by a geometric argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish this section of the tutorial let us check if random numbers generated using `rand()` were indeed $U(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we will add some columns to `df` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>pos</th><th>jumps</th></tr><tr><th></th><th>Int64</th><th>Array…</th><th>Int64</th></tr></thead><tbody><p>10,000,000 rows × 3 columns</p><tr><th>1</th><td>1</td><td>[0.646691, 0.112486, 0.276021]</td><td>3</td></tr><tr><th>2</th><td>2</td><td>[0.651664, 0.0566425, 0.842714]</td><td>3</td></tr><tr><th>3</th><td>3</td><td>[0.950498, 0.96467]</td><td>2</td></tr><tr><th>4</th><td>4</td><td>[0.945775, 0.789904]</td><td>2</td></tr><tr><th>5</th><td>5</td><td>[0.82116, 0.0341601, 0.0945445, 0.314926]</td><td>4</td></tr><tr><th>6</th><td>6</td><td>[0.12781, 0.374187, 0.931115]</td><td>3</td></tr><tr><th>7</th><td>7</td><td>[0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169]</td><td>5</td></tr><tr><th>8</th><td>8</td><td>[0.732, 0.299058]</td><td>2</td></tr><tr><th>9</th><td>9</td><td>[0.449182, 0.875096]</td><td>2</td></tr><tr><th>10</th><td>10</td><td>[0.0462887, 0.698356, 0.365109]</td><td>3</td></tr><tr><th>11</th><td>11</td><td>[0.302478, 0.372575, 0.150508, 0.147329, 0.283401]</td><td>5</td></tr><tr><th>12</th><td>12</td><td>[0.404953, 0.499531, 0.658815]</td><td>3</td></tr><tr><th>13</th><td>13</td><td>[0.515627, 0.260715, 0.59552]</td><td>3</td></tr><tr><th>14</th><td>14</td><td>[0.292462, 0.28858, 0.61816]</td><td>3</td></tr><tr><th>15</th><td>15</td><td>[0.66426, 0.753508]</td><td>2</td></tr><tr><th>16</th><td>16</td><td>[0.0368842, 0.643704, 0.401421]</td><td>3</td></tr><tr><th>17</th><td>17</td><td>[0.525057, 0.61201]</td><td>2</td></tr><tr><th>18</th><td>18</td><td>[0.432577, 0.082207, 0.199058, 0.576082]</td><td>4</td></tr><tr><th>19</th><td>19</td><td>[0.218177, 0.362036, 0.204728, 0.932984]</td><td>4</td></tr><tr><th>20</th><td>20</td><td>[0.827263, 0.0992992, 0.6343]</td><td>3</td></tr><tr><th>21</th><td>21</td><td>[0.132715, 0.775194, 0.869237]</td><td>3</td></tr><tr><th>22</th><td>22</td><td>[0.0396356, 0.79041, 0.431188]</td><td>3</td></tr><tr><th>23</th><td>23</td><td>[0.137658, 0.60808, 0.255054]</td><td>3</td></tr><tr><th>24</th><td>24</td><td>[0.498734, 0.0940369, 0.52509]</td><td>3</td></tr><tr><th>25</th><td>25</td><td>[0.265511, 0.110096, 0.834362]</td><td>3</td></tr><tr><th>26</th><td>26</td><td>[0.633427, 0.337865, 0.112987]</td><td>3</td></tr><tr><th>27</th><td>27</td><td>[0.78299, 0.838042]</td><td>2</td></tr><tr><th>28</th><td>28</td><td>[0.0878598, 0.386568, 0.330579, 0.748041]</td><td>4</td></tr><tr><th>29</th><td>29</td><td>[0.265595, 0.291069, 0.612628]</td><td>3</td></tr><tr><th>30</th><td>30</td><td>[0.705766, 0.508363]</td><td>2</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & pos & jumps\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Array… & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & [0.646691, 0.112486, 0.276021] & 3 \\\\\n",
       "\t2 & 2 & [0.651664, 0.0566425, 0.842714] & 3 \\\\\n",
       "\t3 & 3 & [0.950498, 0.96467] & 2 \\\\\n",
       "\t4 & 4 & [0.945775, 0.789904] & 2 \\\\\n",
       "\t5 & 5 & [0.82116, 0.0341601, 0.0945445, 0.314926] & 4 \\\\\n",
       "\t6 & 6 & [0.12781, 0.374187, 0.931115] & 3 \\\\\n",
       "\t7 & 7 & [0.438939, 0.246862, 0.0118196, 0.0460428, 0.496169] & 5 \\\\\n",
       "\t8 & 8 & [0.732, 0.299058] & 2 \\\\\n",
       "\t9 & 9 & [0.449182, 0.875096] & 2 \\\\\n",
       "\t10 & 10 & [0.0462887, 0.698356, 0.365109] & 3 \\\\\n",
       "\t11 & 11 & [0.302478, 0.372575, 0.150508, 0.147329, 0.283401] & 5 \\\\\n",
       "\t12 & 12 & [0.404953, 0.499531, 0.658815] & 3 \\\\\n",
       "\t13 & 13 & [0.515627, 0.260715, 0.59552] & 3 \\\\\n",
       "\t14 & 14 & [0.292462, 0.28858, 0.61816] & 3 \\\\\n",
       "\t15 & 15 & [0.66426, 0.753508] & 2 \\\\\n",
       "\t16 & 16 & [0.0368842, 0.643704, 0.401421] & 3 \\\\\n",
       "\t17 & 17 & [0.525057, 0.61201] & 2 \\\\\n",
       "\t18 & 18 & [0.432577, 0.082207, 0.199058, 0.576082] & 4 \\\\\n",
       "\t19 & 19 & [0.218177, 0.362036, 0.204728, 0.932984] & 4 \\\\\n",
       "\t20 & 20 & [0.827263, 0.0992992, 0.6343] & 3 \\\\\n",
       "\t21 & 21 & [0.132715, 0.775194, 0.869237] & 3 \\\\\n",
       "\t22 & 22 & [0.0396356, 0.79041, 0.431188] & 3 \\\\\n",
       "\t23 & 23 & [0.137658, 0.60808, 0.255054] & 3 \\\\\n",
       "\t24 & 24 & [0.498734, 0.0940369, 0.52509] & 3 \\\\\n",
       "\t25 & 25 & [0.265511, 0.110096, 0.834362] & 3 \\\\\n",
       "\t26 & 26 & [0.633427, 0.337865, 0.112987] & 3 \\\\\n",
       "\t27 & 27 & [0.78299, 0.838042] & 2 \\\\\n",
       "\t28 & 28 & [0.0878598, 0.386568, 0.330579, 0.748041] & 4 \\\\\n",
       "\t29 & 29 & [0.265595, 0.291069, 0.612628] & 3 \\\\\n",
       "\t30 & 30 & [0.705766, 0.508363] & 2 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×3 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m pos                               \u001b[0m\u001b[1m jumps \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Int64    \u001b[0m\u001b[90m Array…                            \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────────┼────────────────────────────────────────────────────\n",
       "        1 │        1  [0.646691, 0.112486, 0.276021]         3\n",
       "        2 │        2  [0.651664, 0.0566425, 0.842714]        3\n",
       "        3 │        3  [0.950498, 0.96467]                    2\n",
       "        4 │        4  [0.945775, 0.789904]                   2\n",
       "        5 │        5  [0.82116, 0.0341601, 0.0945445, …      4\n",
       "        6 │        6  [0.12781, 0.374187, 0.931115]          3\n",
       "        7 │        7  [0.438939, 0.246862, 0.0118196, …      5\n",
       "        8 │        8  [0.732, 0.299058]                      2\n",
       "        9 │        9  [0.449182, 0.875096]                   2\n",
       "       10 │       10  [0.0462887, 0.698356, 0.365109]        3\n",
       "       11 │       11  [0.302478, 0.372575, 0.150508, 0…      5\n",
       "    ⋮     │    ⋮                      ⋮                    ⋮\n",
       "  9999991 │  9999991  [0.700468, 0.220524, 0.347931]         3\n",
       "  9999992 │  9999992  [0.231368, 0.862016]                   2\n",
       "  9999993 │  9999993  [0.869351, 0.444795]                   2\n",
       "  9999994 │  9999994  [0.821356, 0.509054]                   2\n",
       "  9999995 │  9999995  [0.589245, 0.669708]                   2\n",
       "  9999996 │  9999996  [0.806262, 0.734397]                   2\n",
       "  9999997 │  9999997  [0.216506, 0.430571, 0.283787, 0…      4\n",
       "  9999998 │  9999998  [0.0100723, 0.836315, 0.942299]        3\n",
       "  9999999 │  9999999  [0.499669, 0.25214, 0.964065]          3\n",
       " 10000000 │ 10000000  [0.663339, 0.887989]                   2\n",
       "\u001b[36m                                           9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>first</th><th>last</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>10,000,000 rows × 2 columns</p><tr><th>1</th><td>0.646691</td><td>0.276021</td></tr><tr><th>2</th><td>0.651664</td><td>0.842714</td></tr><tr><th>3</th><td>0.950498</td><td>0.96467</td></tr><tr><th>4</th><td>0.945775</td><td>0.789904</td></tr><tr><th>5</th><td>0.82116</td><td>0.314926</td></tr><tr><th>6</th><td>0.12781</td><td>0.931115</td></tr><tr><th>7</th><td>0.438939</td><td>0.496169</td></tr><tr><th>8</th><td>0.732</td><td>0.299058</td></tr><tr><th>9</th><td>0.449182</td><td>0.875096</td></tr><tr><th>10</th><td>0.0462887</td><td>0.365109</td></tr><tr><th>11</th><td>0.302478</td><td>0.283401</td></tr><tr><th>12</th><td>0.404953</td><td>0.658815</td></tr><tr><th>13</th><td>0.515627</td><td>0.59552</td></tr><tr><th>14</th><td>0.292462</td><td>0.61816</td></tr><tr><th>15</th><td>0.66426</td><td>0.753508</td></tr><tr><th>16</th><td>0.0368842</td><td>0.401421</td></tr><tr><th>17</th><td>0.525057</td><td>0.61201</td></tr><tr><th>18</th><td>0.432577</td><td>0.576082</td></tr><tr><th>19</th><td>0.218177</td><td>0.932984</td></tr><tr><th>20</th><td>0.827263</td><td>0.6343</td></tr><tr><th>21</th><td>0.132715</td><td>0.869237</td></tr><tr><th>22</th><td>0.0396356</td><td>0.431188</td></tr><tr><th>23</th><td>0.137658</td><td>0.255054</td></tr><tr><th>24</th><td>0.498734</td><td>0.52509</td></tr><tr><th>25</th><td>0.265511</td><td>0.834362</td></tr><tr><th>26</th><td>0.633427</td><td>0.112987</td></tr><tr><th>27</th><td>0.78299</td><td>0.838042</td></tr><tr><th>28</th><td>0.0878598</td><td>0.748041</td></tr><tr><th>29</th><td>0.265595</td><td>0.612628</td></tr><tr><th>30</th><td>0.705766</td><td>0.508363</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& first & last\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.646691 & 0.276021 \\\\\n",
       "\t2 & 0.651664 & 0.842714 \\\\\n",
       "\t3 & 0.950498 & 0.96467 \\\\\n",
       "\t4 & 0.945775 & 0.789904 \\\\\n",
       "\t5 & 0.82116 & 0.314926 \\\\\n",
       "\t6 & 0.12781 & 0.931115 \\\\\n",
       "\t7 & 0.438939 & 0.496169 \\\\\n",
       "\t8 & 0.732 & 0.299058 \\\\\n",
       "\t9 & 0.449182 & 0.875096 \\\\\n",
       "\t10 & 0.0462887 & 0.365109 \\\\\n",
       "\t11 & 0.302478 & 0.283401 \\\\\n",
       "\t12 & 0.404953 & 0.658815 \\\\\n",
       "\t13 & 0.515627 & 0.59552 \\\\\n",
       "\t14 & 0.292462 & 0.61816 \\\\\n",
       "\t15 & 0.66426 & 0.753508 \\\\\n",
       "\t16 & 0.0368842 & 0.401421 \\\\\n",
       "\t17 & 0.525057 & 0.61201 \\\\\n",
       "\t18 & 0.432577 & 0.576082 \\\\\n",
       "\t19 & 0.218177 & 0.932984 \\\\\n",
       "\t20 & 0.827263 & 0.6343 \\\\\n",
       "\t21 & 0.132715 & 0.869237 \\\\\n",
       "\t22 & 0.0396356 & 0.431188 \\\\\n",
       "\t23 & 0.137658 & 0.255054 \\\\\n",
       "\t24 & 0.498734 & 0.52509 \\\\\n",
       "\t25 & 0.265511 & 0.834362 \\\\\n",
       "\t26 & 0.633427 & 0.112987 \\\\\n",
       "\t27 & 0.78299 & 0.838042 \\\\\n",
       "\t28 & 0.0878598 & 0.748041 \\\\\n",
       "\t29 & 0.265595 & 0.612628 \\\\\n",
       "\t30 & 0.705766 & 0.508363 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10000000×2 DataFrame\u001b[0m\n",
       "\u001b[1m      Row \u001b[0m│\u001b[1m first     \u001b[0m\u001b[1m last     \u001b[0m\n",
       "\u001b[1m          \u001b[0m│\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "──────────┼─────────────────────\n",
       "        1 │ 0.646691   0.276021\n",
       "        2 │ 0.651664   0.842714\n",
       "        3 │ 0.950498   0.96467\n",
       "        4 │ 0.945775   0.789904\n",
       "        5 │ 0.82116    0.314926\n",
       "        6 │ 0.12781    0.931115\n",
       "        7 │ 0.438939   0.496169\n",
       "        8 │ 0.732      0.299058\n",
       "        9 │ 0.449182   0.875096\n",
       "       10 │ 0.0462887  0.365109\n",
       "       11 │ 0.302478   0.283401\n",
       "    ⋮     │     ⋮         ⋮\n",
       "  9999991 │ 0.700468   0.347931\n",
       "  9999992 │ 0.231368   0.862016\n",
       "  9999993 │ 0.869351   0.444795\n",
       "  9999994 │ 0.821356   0.509054\n",
       "  9999995 │ 0.589245   0.669708\n",
       "  9999996 │ 0.806262   0.734397\n",
       "  9999997 │ 0.216506   0.335015\n",
       "  9999998 │ 0.0100723  0.942299\n",
       "  9999999 │ 0.499669   0.964065\n",
       " 10000000 │ 0.663339   0.887989\n",
       "\u001b[36m            9999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = select(df, :pos => ByRow(first) => :first, :pos => ByRow(last) => :last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(df_test.first, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far all looks good. But let us look at the distribution of the last dawn random number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3df1RU553H8c8UZEBXJohhcCyJ6EmNlDRtoEU0CbqJYOKPmHZXUtqp9KREVhtFTKIkMVWbgBiPzVajiVl37aaJeDaW1DRqwE1FjeAPIlaNP5IqUauINmRGjQXEu394uOuAUdEBhPt+nTPnyL3feea5d7PLZ7/PcwebYRiGAAAALOgb7T0BAACA9kIQAgAAlkUQAgAAlkUQAgAAlkUQAgAAlkUQAgAAlkUQAgAAlkUQAgAAlhXY3hO4mV24cEHHjh1T9+7dZbPZ2ns6AADgGhiGodOnT8vlcukb37hyz4cgdAXHjh1TVFRUe08DAABchyNHjuib3/zmFWsIQlfQvXt3SRdvZGhoaDvPBgAAXAuv16uoqCjz9/iVEISuoHE5LDQ0lCAEAEAHcy3bWtgsDQAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALCuwvScAAACsoc/095sdq5wzoh1m8v/oCAEAAMsiCAEAAMtiaQwAALSKyy2F3WwIQgAA4IZ1hNBzOQQhAADQYh01+DTFHiEAAGBZdIQAAMAVdZbuz+XQEQIAAJZFRwgAAPjozB2gpugIAQAAyyIIAQAAy2JpDAAAC7PSMtjl0BECAACWRRACAACWxdIYAAAWYvWlsKYIQgAAdFKEnqtjaQwAAFgWQQgAAFhWi4PQhg0bNGrUKLlcLtlsNr377rvNavbu3avRo0fL4XCoe/fuGjhwoA4fPmyer62t1ZNPPqmePXuqW7duGj16tI4ePeozxuHDhzVq1Ch169ZNPXv21KRJk1RXV+dTU1JSori4OAUHB6tv37567bXXms1l0aJFio6OVnBwsOLi4rRx48aWXjIAAB1Cn+nv+7xwdS0OQmfPntXdd9+thQsXXvb8X//6V91777268847tX79eu3cuVMzZsxQcHCwWZOVlaXCwkIVFBRo06ZNOnPmjEaOHKmGhgZJUkNDg0aMGKGzZ89q06ZNKigo0MqVKzV16lRzjEOHDunhhx/Wfffdpx07dujZZ5/VpEmTtHLlSrNmxYoVysrK0nPPPacdO3bovvvu00MPPeQTygAAgHXZDMMwrvvNNpsKCws1ZswY89hjjz2mLl266M0337zsezwej2699Va9+eabSk1NlSQdO3ZMUVFRWr16tVJSUrRmzRqNHDlSR44ckcvlkiQVFBQoPT1d1dXVCg0N1bRp07Rq1Srt3bvXHDszM1M7d+5UaWmpJCkhIUH33HOPFi9ebNYMGDBAY8aMUV5e3lWvz+v1yuFwyOPxKDQ0tOU3CACANtQRu0CVc0b4fcyW/P726x6hCxcu6P3339e3vvUtpaSkKCIiQgkJCT7LZ+Xl5aqvr1dycrJ5zOVyKTY2Vps3b5YklZaWKjY21gxBkpSSkqLa2lqVl5ebNZeO0Vizfft21dfXq66uTuXl5c1qkpOTzc9pqra2Vl6v1+cFAMDNqOkyWEcMQTcDvwah6upqnTlzRnPmzNHw4cNVVFSkRx99VD/84Q9VUlIiSaqqqlJQUJDCwsJ83ut0OlVVVWXWOJ1On/NhYWEKCgq6Yo3T6dT58+d16tQpnTp1Sg0NDZetaRyjqby8PDkcDvMVFRV1/TcDAADc9PzeEZKkRx55RFOmTNF3v/tdTZ8+XSNHjrzsRuZLGYYhm81m/nzpv6+1pnGV72o1lxtbknJycuTxeMzXkSNHrjhnAADQsfn1CxV79uypwMBAxcTE+BwfMGCANm3aJEmKjIxUXV2dampqfLpC1dXVGjRokFmzZcsWnzFqampUX19vdngiIyObdXaqq6sVGBio8PBwGYahgICAy9Y07RI1stvtstvt13HlAAC0Lpa+WodfO0JBQUH6/ve/r/379/scP3DggG6//XZJUlxcnLp06aLi4mLz/PHjx7V7924zCCUmJmr37t06fvy4WVNUVCS73a64uDiz5tIxGmvi4+PVpUsXBQUFKS4urllNcXGx+TkAANyM2P/TdlrcETpz5ow+++wz8+dDhw6poqJCPXr00G233aann35aqampuv/++zV06FCtXbtW7733ntavXy9JcjgcevzxxzV16lSFh4erR48eeuqpp3TXXXfpwQcflHRxQ3NMTIzcbrdefvllffHFF3rqqaeUkZFh7v7OzMzUwoULlZ2drYyMDJWWlmrp0qVavny5Obfs7Gy53W7Fx8crMTFRS5Ys0eHDh5WZmXkj9wwAAHQSLX58fv369Ro6dGiz4+PGjdOyZcskSf/5n/+pvLw8HT16VP3799esWbP0yCOPmLX/+Mc/9PTTT+vtt9/WuXPn9MADD2jRokU+m5MPHz6sCRMm6MMPP1RISIjS0tI0b948n6WrkpISTZkyRXv27JHL5dK0adOahZxFixZp7ty5On78uGJjY/Wb3/xG999//zVdK4/PAwDagpU7Pu39+PwNfY9QZ0cQAgC0BYKQf7Xb9wgBAAB0JH59agwAAFyZlbs/NyM6QgAAwLIIQgAAwLJYGgMAoBWxFHZzoyMEAAAsi44QAAB+Qven46EjBAAALIsgBAAALIulMQAArhNLYR0fHSEAAGBZdIQAALgGdH86J4IQAACXQfCxBpbGAACAZRGEAACAZRGEAACAZbFHCABgeewHsi6CEADAcgg+aMTSGAAAsCyCEAAAsCyCEAAAsCz2CAEAOjX2A+FK6AgBAADLIggBAADLIggBAADLYo8QAKDDYv8PbhQdIQAAYFkEIQAAYFkEIQAAYFnsEQIAdBjsCYK/tbgjtGHDBo0aNUoul0s2m03vvvvu19aOHz9eNptNr7zyis/xmpoaud1uORwOORwOud1uffnllz41u3btUlJSkkJCQtS7d2/Nnj1bhmH41KxcuVIxMTGy2+2KiYlRYWGhz3nDMDRz5ky5XC6FhIRoyJAh2rNnT0svGQAAdFItDkJnz57V3XffrYULF16x7t1339WWLVvkcrmanUtLS1NFRYXWrl2rtWvXqqKiQm632zzv9Xo1bNgwuVwubdu2TQsWLNC8efM0f/58s6a0tFSpqalyu93auXOn3G63xo4dqy1btpg1c+fO1fz587Vw4UJt27ZNkZGRGjZsmE6fPt3SywYAAJ2QzWjaZmnJm202FRYWasyYMT7H//a3vykhIUEffPCBRowYoaysLGVlZUmS9u7dq5iYGJWVlSkhIUGSVFZWpsTERO3bt0/9+/fX4sWLlZOToxMnTshut0uS5syZowULFujo0aOy2WxKTU2V1+vVmjVrzM8dPny4wsLCtHz5chmGIZfLpaysLE2bNk2SVFtbK6fTqfz8fI0fP/6q1+f1euVwOOTxeBQaGnq9twkAcB1YBrOGyjkj/D5mS35/+32z9IULF+R2u/X000/r29/+drPzpaWlcjgcZgiSpIEDB8rhcGjz5s1mTVJSkhmCJCklJUXHjh1TZWWlWZOcnOwzdkpKijnGoUOHVFVV5VNjt9uVlJRk1jRVW1srr9fr8wIAAJ2X3zdL5+fnKzAwUJMmTbrs+aqqKkVERDQ7HhERoaqqKrOmT58+PuedTqd5Ljo6WlVVVeaxS2suHePS911a8/nnn192bnl5eZo1a9ZVrhAA0BroAKE9+LUjVF5ern//93/XsmXLZLPZvrbucucMw/A53rSmcQXvajVNj11LTaOcnBx5PB7zdeTIka+9BgAA0PH5tSO0ceNGVVdX67bbbjOPNTQ0aOrUqXrllVdUWVmpyMhInThxotl7T548aXZvIiMjzY5Oo+rqakm6as2l56WLnaFevXpdtqYpu93usxwHAGgddH9ws/BrR8jtdusvf/mLKioqzJfL5dLTTz+tDz74QJKUmJgoj8ejrVu3mu/bsmWLPB6PBg0aZNZs2LBBdXV1Zk1RUZFcLpe5ZJaYmKji4mKfzy8qKjLHiI6OVmRkpE9NXV2dSkpKzBoAAGBtLe4InTlzRp999pn586FDh1RRUaEePXrotttuU3h4uE99ly5dFBkZqf79+0uSBgwYoOHDhysjI0Ovv/66JOmJJ57QyJEjzZq0tDTNmjVL6enpevbZZ/Xpp58qNzdXL7zwgrmsNXnyZN1///3Kz8/XI488oj/+8Y9at26dNm3aJOniklhWVpZyc3N1xx136I477lBubq66du2qtLS067hVAACgs2lxENq+fbuGDh1q/pydnS1JGjdunJYtW3ZNY7z11luaNGmS+UTX6NGjfb6XyOFwqLi4WBMnTlR8fLzCwsKUnZ1tfpYkDRo0SAUFBXr++ec1Y8YM9evXTytWrPB5Gu2ZZ57RuXPnNGHCBNXU1CghIUFFRUXq3r17Sy8bAAB0Qjf0PUKdHd8jBACtgz1CaNTe3yPE3xoDALQ6gg9uVvz1eQAAYFl0hAAAfkX3Bx0JHSEAAGBZdIQAADeEDhA6MjpCAADAsghCAADAslgaAwBcM5bB0NkQhAAAX4vgg86OpTEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZbJYGAEhiYzSsiY4QAACwLDpCAGBRdIAAOkIAAMDCCEIAAMCyWBoDAAtgGQy4PDpCAADAsghCAADAsghCAADAstgjBACdEHuCgGtDRwgAAFgWHSEA6ODo/gDXj44QAACwLIIQAACwLIIQAACwLPYIAUAHw54gwH/oCAEAAMtqcRDasGGDRo0aJZfLJZvNpnfffdc8V19fr2nTpumuu+5St27d5HK59LOf/UzHjh3zGaOmpkZut1sOh0MOh0Nut1tffvmlT82uXbuUlJSkkJAQ9e7dW7Nnz5ZhGD41K1euVExMjOx2u2JiYlRYWOhz3jAMzZw5Uy6XSyEhIRoyZIj27NnT0ksGgHbTZ/r7zV4A/KfFQejs2bO6++67tXDhwmbnvvrqK3388ceaMWOGPv74Y/3hD3/QgQMHNHr0aJ+6tLQ0VVRUaO3atVq7dq0qKirkdrvN816vV8OGDZPL5dK2bdu0YMECzZs3T/PnzzdrSktLlZqaKrfbrZ07d8rtdmvs2LHasmWLWTN37lzNnz9fCxcu1LZt2xQZGalhw4bp9OnTLb1sAADQCdmMpm2WlrzZZlNhYaHGjBnztTXbtm3TD37wA33++ee67bbbtHfvXsXExKisrEwJCQmSpLKyMiUmJmrfvn3q37+/Fi9erJycHJ04cUJ2u12SNGfOHC1YsEBHjx6VzWZTamqqvF6v1qxZY37W8OHDFRYWpuXLl8swDLlcLmVlZWnatGmSpNraWjmdTuXn52v8+PFXvT6v1yuHwyGPx6PQ0NDrvU0AcN3oAKGzq5wzwu9jtuT3d6vvEfJ4PLLZbLrlllskXezkOBwOMwRJ0sCBA+VwOLR582azJikpyQxBkpSSkqJjx46psrLSrElOTvb5rJSUFHOMQ4cOqaqqyqfGbrcrKSnJrGmqtrZWXq/X5wUAADqvVn1q7B//+IemT5+utLQ0M5FVVVUpIiKiWW1ERISqqqrMmj59+vicdzqd5rno6GhVVVWZxy6tuXSMS993ac3nn39+2fnm5eVp1qxZLbxKAPAfOkBA22q1jlB9fb0ee+wxXbhwQYsWLfI5Z7PZmtUbhuFzvGlN4wre1WqaHruWmkY5OTnyeDzm68iRI193eQAAoBNolY5QfX29xo4dq0OHDunDDz/0WZ+LjIzUiRMnmr3n5MmTZvcmMjLS7Og0qq6ulqSr1lx6XrrYGerVq9dla5qy2+0+y3EA0Jro/gDtz+8docYQ9Omnn2rdunUKDw/3OZ+YmCiPx6OtW7eax7Zs2SKPx6NBgwaZNRs2bFBdXZ1ZU1RUJJfLZS6ZJSYmqri42GfsoqIic4zo6GhFRkb61NTV1amkpMSsAQAA1tbijtCZM2f02WefmT8fOnRIFRUV6tGjh1wul/7lX/5FH3/8sf70pz+poaHB7Nr06NFDQUFBGjBggIYPH66MjAy9/vrrkqQnnnhCI0eOVP/+/SVdfLx+1qxZSk9P17PPPqtPP/1Uubm5euGFF8xlrcmTJ+v+++9Xfn6+HnnkEf3xj3/UunXrtGnTJkkXl8SysrKUm5urO+64Q3fccYdyc3PVtWtXpaWl3dhdAwAAnUKLH59fv369hg4d2uz4uHHjNHPmTEVHR1/2fX/+8581ZMgQSdIXX3yhSZMmadWqVZKk0aNHa+HCheaTZdLFL1ScOHGitm7dqrCwMGVmZvoEIUl655139Pzzz+vgwYPq16+fXnrpJf3whz80zxuGoVmzZun1119XTU2NEhIS9Oqrryo2NvaarpXH5wG0JpbGgPZ/fP6GvkeosyMIAWhNBCGg/YMQf3QVANoIwQe4+fBHVwEAgGXREQKAVkD3B+gY6AgBAADLoiMEAH5ABwjomOgIAQAAyyIIAQAAyyIIAQAAy2KPEAC0EPuBgM6DjhAAALAsghAAALAsghAAALAs9ggBwBWwHwjo3OgIAQAAyyIIAQAAy2JpDAAuwVIYYC10hAAAgGURhAAAgGWxNAbAslgGA0BHCAAAWBZBCAAAWBZBCAAAWBZ7hABYBnuCADRFRwgAAFgWQQgAAFgWS2MAOiWWwQBcCzpCAADAsghCAADAsghCAADAstgjBKBTYE8QgOvR4o7Qhg0bNGrUKLlcLtlsNr377rs+5w3D0MyZM+VyuRQSEqIhQ4Zoz549PjU1NTVyu91yOBxyOBxyu9368ssvfWp27dqlpKQkhYSEqHfv3po9e7YMw/CpWblypWJiYmS32xUTE6PCwsIWzwUAAFhXi4PQ2bNndffdd2vhwoWXPT937lzNnz9fCxcu1LZt2xQZGalhw4bp9OnTZk1aWpoqKiq0du1arV27VhUVFXK73eZ5r9erYcOGyeVyadu2bVqwYIHmzZun+fPnmzWlpaVKTU2V2+3Wzp075Xa7NXbsWG3ZsqVFcwEAANZlM5q2WVryZptNhYWFGjNmjKSLHRiXy6WsrCxNmzZNklRbWyun06n8/HyNHz9ee/fuVUxMjMrKypSQkCBJKisrU2Jiovbt26f+/ftr8eLFysnJ0YkTJ2S32yVJc+bM0YIFC3T06FHZbDalpqbK6/VqzZo15nyGDx+usLAwLV++/JrmcjVer1cOh0Mej0ehoaHXe5sA+BnLYEDnUTlnhN/HbMnvb79ulj506JCqqqqUnJxsHrPb7UpKStLmzZslXezkOBwOMwRJ0sCBA+VwOHxqkpKSzBAkSSkpKTp27JgqKyvNmks/p7GmcYxrmQsAALA2vwahqqoqSZLT6fQ57nQ6zXNVVVWKiIho9t6IiAifmsuNcelnfF3NpeevNpemamtr5fV6fV4AAKDzapWnxmw2m8/PhmH4HGt6/lpqGlfwrlbT9Ni11DTKy8vTrFmzLnsOQPthKQxAa/FrRygyMlKSmnVcqqurzc5MZGSkTpw40ey9J0+e9Km53BiSrlpz6fmrzaWpnJwceTwe83XkyJGrXDEAAOjI/BqEoqOjFRkZqeLiYvNYXV2dSkpKNGjQIElSYmKiPB6Ptm7datZs2bJFHo/Hp2bDhg2qq6sza4qKiuRyudSnTx+z5tLPaaxpHONa5tKU3W5XaGiozwsAAHReLQ5CZ86cUUVFhSoqKiRd3JRcUVGhw4cPy2azKSsrS7m5uSosLNTu3buVnp6url27Ki0tTZI0YMAADR8+XBkZGSorK1NZWZkyMjI0cuRI9e/fX9LFx+vtdrvS09O1e/duFRYWKjc3V9nZ2eay1uTJk1VUVKT8/Hzt27dP+fn5WrdunbKysiTpmuYCAACsrcV7hLZv366hQ4eaP2dnZ0uSxo0bp2XLlumZZ57RuXPnNGHCBNXU1CghIUFFRUXq3r27+Z633npLkyZNMp/oGj16tM/3EjkcDhUXF2vixImKj49XWFiYsrOzzc+SpEGDBqmgoEDPP/+8ZsyYoX79+mnFihU+T6Ndy1wA3FzYDwSgLd3Q9wh1dnyPEND2CEKAtXSq7xECAADoSAhCAADAsghCAADAsghCAADAslrlm6UB4FqxORpAe6IjBAAALIuOEIA2Q/cHwM2GjhAAALAsghAAALAslsYAtBqWwgDc7OgIAQAAyyIIAQAAy2JpDIBfsAwGoCOiIwQAACyLIAQAACyLIAQAACyLIAQAACyLzdIArgubowF0BnSEAACAZRGEAACAZbE0BuCqWAYD0FnREQIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJbFU2MAmuEpMQBWQUcIAABYFkEIAABYFktjgMWxDAbAyugIAQAAy/J7EDp//ryef/55RUdHKyQkRH379tXs2bN14cIFs8YwDM2cOVMul0shISEaMmSI9uzZ4zNOTU2N3G63HA6HHA6H3G63vvzyS5+aXbt2KSkpSSEhIerdu7dmz54twzB8alauXKmYmBjZ7XbFxMSosLDQ35cMAAA6KL8vjeXn5+u1117T7373O33729/W9u3b9fOf/1wOh0OTJ0+WJM2dO1fz58/XsmXL9K1vfUsvvviihg0bpv3796t79+6SpLS0NB09elRr166VJD3xxBNyu9167733JEler1fDhg3T0KFDtW3bNh04cEDp6enq1q2bpk6dKkkqLS1Vamqqfv3rX+vRRx9VYWGhxo4dq02bNikhIcHflw50CCyFAcD/sxlNWyg3aOTIkXI6nVq6dKl57Ec/+pG6du2qN998U4ZhyOVyKSsrS9OmTZMk1dbWyul0Kj8/X+PHj9fevXsVExOjsrIyM7CUlZUpMTFR+/btU//+/bV48WLl5OToxIkTstvtkqQ5c+ZowYIFOnr0qGw2m1JTU+X1erVmzRpzLsOHD1dYWJiWL19+1Wvxer1yOBzyeDwKDQ31520C2g1BCMDNpHLOCL+P2ZLf335fGrv33nv1v//7vzpw4IAkaefOndq0aZMefvhhSdKhQ4dUVVWl5ORk8z12u11JSUnavHmzpIudHIfD4dO1GThwoBwOh09NUlKSGYIkKSUlRceOHVNlZaVZc+nnNNY0jtFUbW2tvF6vzwsAAHRefl8amzZtmjwej+68804FBASooaFBL730kn784x9LkqqqqiRJTqfT531Op1Off/65WRMREdFs7IiICPP9VVVV6tOnT7MxGs9FR0erqqrqsp/TOEZTeXl5mjVrVguvGAAAdFR+D0IrVqzQ73//e7399tv69re/rYqKCmVlZcnlcmncuHFmnc1m83mfYRg+x5qev5aaxlW+q9VcbmxJysnJUXZ2tvmz1+tVVFTU114rcLNjGQwArszvQejpp5/W9OnT9dhjj0mS7rrrLn3++efKy8vTuHHjFBkZKeli16ZXr17m+6qrq83uTWRkpE6cONFs7JMnT/rUNO3sVFdXS9JVa5p2iRrZ7XafpTYAANC5+X2P0FdffaVvfMN32ICAAPPx+ejoaEVGRqq4uNg8X1dXp5KSEg0aNEiSlJiYKI/Ho61bt5o1W7Zskcfj8anZsGGD6urqzJqioiK5XC5zySwxMdHncxprGscAAADW5vcgNGrUKL300kt6//33VVlZqcLCQs2fP1+PPvqopItLVVlZWcrNzVVhYaF2796t9PR0de3aVWlpaZKkAQMGaPjw4crIyFBZWZnKysqUkZGhkSNHqn///pIuPl5vt9uVnp6u3bt3q7CwULm5ucrOzjaXviZPnqyioiLl5+dr3759ys/P17p165SVleXvywYAAB2Q3x+fP336tGbMmKHCwkJVV1fL5XLpxz/+sV544QUFBQVJurhPZ9asWXr99ddVU1OjhIQEvfrqq4qNjTXH+eKLLzRp0iStWrVKkjR69GgtXLhQt9xyi1mza9cuTZw4UVu3blVYWJgyMzP1wgsv+OwBeuedd/T888/r4MGD6tevn1566SX98Ic/vKZr4fF5dDTsCQLQ0bT34/N+D0KdCUEIHQ1BCEBH095BiL81BgAALIsgBAAALIsgBAAALMvv3yMEoG2wHwgAbhwdIQAAYFl0hIAOgg4QAPgfHSEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZPDUG3IR4QgwA2gYdIQAAYFkEIQAAYFkEIQAAYFnsEQJuAuwJAoD2QUcIAABYFkEIAABYFkEIAABYFnuEgDbGfiAAuHnQEQIAAJZFEAIAAJZFEAIAAJbFHiGglbEnCABuXnSEAACAZRGEAACAZRGEAACAZRGEAACAZbFZGvAjNkYDQMdCRwgAAFhWqwShv/3tb/rpT3+q8PBwde3aVd/97ndVXl5unjcMQzNnzpTL5VJISIiGDBmiPXv2+IxRU1Mjt9sth8Mhh8Mht9utL7/80qdm165dSkpKUkhIiHr37q3Zs2fLMAyfmpUrVyomJkZ2u10xMTEqLCxsjUsGAAAdkN+XxmpqajR48GANHTpUa9asUUREhP7617/qlltuMWvmzp2r+fPna9myZfrWt76lF198UcOGDdP+/fvVvXt3SVJaWpqOHj2qtWvXSpKeeOIJud1uvffee5Ikr9erYcOGaejQodq2bZsOHDig9PR0devWTVOnTpUklZaWKjU1Vb/+9a/16KOPqrCwUGPHjtWmTZuUkJDg70uHBbEUBgAdm81o2kK5QdOnT9dHH32kjRs3Xva8YRhyuVzKysrStGnTJEm1tbVyOp3Kz8/X+PHjtXfvXsXExKisrMwMLGVlZUpMTNS+ffvUv39/LV68WDk5OTpx4oTsdrskac6cOVqwYIGOHj0qm82m1NRUeb1erVmzxvz84cOHKywsTMuXL7/qtXi9XjkcDnk8HoWGht7orUEnRBACgBtTOWeE38dsye9vvy+NrVq1SvHx8frXf/1XRURE6Hvf+57eeOMN8/yhQ4dUVVWl5ORk85jdbldSUpI2b94s6WInx+Fw+HRtBg4cKIfD4VOTlJRkhrfsu70AABejSURBVCBJSklJ0bFjx1RZWWnWXPo5jTWNYzRVW1srr9fr8wIAAJ2X34PQwYMHtXjxYt1xxx364IMPlJmZqUmTJum///u/JUlVVVWSJKfT6fM+p9NpnquqqlJERESzsSMiInxqLjfGpZ/xdTWN55vKy8sz9yQ5HA5FRUW16NoBAEDH4vc9QhcuXFB8fLxyc3MlSd/73ve0Z88eLV68WD/72c/MOpvN5vM+wzB8jjU9fy01jat8V6u53NiSlJOTo+zsbPNnr9dLGIKJZTAA6Hz83hHq1auXYmJifI4NGDBAhw8fliRFRkZKUrOuTHV1tdm9iYyM1IkTJ5qNffLkSZ+ay40h6ao1TbtEjex2u0JDQ31eAACg8/J7EBo8eLD279/vc+zAgQO6/fbbJUnR0dGKjIxUcXGxeb6urk4lJSUaNGiQJCkxMVEej0dbt241a7Zs2SKPx+NTs2HDBtXV1Zk1RUVFcrlc6tOnj1lz6ec01jSOAQAArM3vQWjKlCkqKytTbm6uPvvsM7399ttasmSJJk6cKOniUlVWVpZyc3NVWFio3bt3Kz09XV27dlVaWpqkix2k4cOHKyMjQ2VlZSorK1NGRoZGjhyp/v37S7r4eL3dbld6erp2796twsJC5ebmKjs721z6mjx5soqKipSfn699+/YpPz9f69atU1ZWlr8vGwAAdEB+3yP0/e9/X4WFhcrJydHs2bMVHR2tV155RT/5yU/MmmeeeUbnzp3ThAkTVFNTo4SEBBUVFZnfISRJb731liZNmmQ+9TV69GgtXLjQPO9wOFRcXKyJEycqPj5eYWFhys7O9tnjM2jQIBUUFOj555/XjBkz1K9fP61YsYLvEAIAAJJa4XuEOhO+R8ja2BwNAK2v032PEAAAQEdBEAIAAJZFEAIAAJZFEAIAAJbl96fGgI6IjdEAYE10hAAAgGURhAAAgGURhAAAgGURhAAAgGWxWRqWxOZoAIBERwgAAFgYQQgAAFgWQQgAAFgWe4TQ6bEfCADwdegIAQAAyyIIAQAAyyIIAQAAy2KPEDod9gQBAK4VHSEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZPDWGDo0nxAAAN4KOEAAAsCyCEAAAsCyCEAAAsCz2CKFDYU8QAMCf6AgBAADLIggBAADLavUglJeXJ5vNpqysLPNYbW2tnnzySfXs2VPdunXT6NGjdfToUZ/3HT58WKNGjVK3bt3Us2dPTZo0SXV1dT41JSUliouLU3BwsPr27avXXnut2ecvWrRI0dHRCg4OVlxcnDZu3Ng6FwoAADqcVt0jtG3bNi1ZskTf+c53fI5nZWXpvffeU0FBgcLDwzV16lSNHDlS5eXlCggIUENDg0aMGKFbb71VmzZt0t///neNGzdOhmFowYIFkqRDhw7p4YcfVkZGhn7/+9/ro48+0oQJE3TrrbfqRz/6kSRpxYoVysrK0qJFizR48GC9/vrreuihh/TJJ5/otttua81Lhx+wHwgA0NpshmEYrTHwmTNndM8992jRokV68cUX9d3vflevvPKKPB6Pbr31Vr355ptKTU2VJB07dkxRUVFavXq1UlJStGbNGo0cOVJHjhyRy+WSJBUUFCg9PV3V1dUKDQ3VtGnTtGrVKu3du9f8zMzMTO3cuVOlpaWSpISEBN1zzz1avHixWTNgwACNGTNGeXl5V70Gr9crh8Mhj8ej0NBQf94eXAOCEAB0fpVzRvh9zJb8/m61pbGJEydqxIgRevDBB32Ol5eXq76+XsnJyeYxl8ul2NhYbd68WZJUWlqq2NhYMwRJUkpKimpra1VeXm7WXDpGY8327dtVX1+vuro6lZeXN6tJTk42P6ep2tpaeb1enxcAAOi8WmVprKCgQB9//LG2bdvW7FxVVZWCgoIUFhbmc9zpdKqqqsqscTqdPufDwsIUFBR0xRqn06nz58/r1KlTMgxDDQ0Nl61pHKOpvLw8zZo1q2UXCwAAOiy/B6EjR45o8uTJKioqUnBw8DW/zzAM2Ww28+dL/32tNY2rfDabzeffVxrjUjk5OcrOzjZ/9nq9ioqKuuZrwI1hKQwA0Nb8vjRWXl6u6upqxcXFKTAwUIGBgSopKdFvf/tbBQYGyul0qq6uTjU1NT7vq66uNrs3kZGRzbo2NTU1qq+vv2JNdXW1AgMDFR4erp49eyogIOCyNU27RI3sdrtCQ0N9XgAAoPPyexB64IEHtGvXLlVUVJiv+Ph4/eQnPzH/3aVLFxUXF5vvOX78uHbv3q1BgwZJkhITE7V7924dP37crCkqKpLdbldcXJxZc+kYjTWN4wcFBSkuLq5ZTXFxsfk5AADA2vy+NNa9e3fFxsb6HOvWrZvCw8PN448//rimTp2q8PBw9ejRQ0899ZTuuusuc2N1cnKyYmJi5Ha79fLLL+uLL77QU089pYyMDLNLk5mZqYULFyo7O1sZGRkqLS3V0qVLtXz5cvNzs7Oz5Xa7FR8fr8TERC1ZskSHDx9WZmamvy8bAAB0QO3yt8Z+85vfKDAwUGPHjtW5c+f0wAMPaNmyZQoICJAkBQQE6P3339eECRM0ePBghYSEKC0tTfPmzTPHiI6O1urVqzVlyhS9+uqrcrlc+u1vf2t+h5Akpaam6u9//7tmz56t48ePKzY2VqtXr9btt9/e5tcMAABuPq32PUKdAd8j1LbYLA0A1tPe3yPEX59HuyD0AABuBvzRVQAAYFkEIQAAYFkEIQAAYFkEIQAAYFlslkabYHM0AOBmREcIAABYFkEIAABYFkEIAABYFnuE4HfsBwIAdBR0hAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGXx1BhuGE+JAQA6KjpCAADAsghCAADAsghCAADAstgjhBZhPxAAoDOhIwQAACyLIAQAACyLIAQAACyLIAQAACyLzdK4IjZHAwA6MzpCAADAsghCAADAsghCAADAsghCAADAsghCAADAsvwehPLy8vT9739f3bt3V0REhMaMGaP9+/f71NTW1urJJ59Uz5491a1bN40ePVpHjx71qTl8+LBGjRqlbt26qWfPnpo0aZLq6up8akpKShQXF6fg4GD17dtXr732WrP5LFq0SNHR0QoODlZcXJw2btzo70vuNPpMf7/ZCwCAzszvQaikpEQTJ05UWVmZiouLdf78eSUnJ+vs2bNmTVZWlgoLC1VQUKBNmzbpzJkzGjlypBoaGiRJDQ0NGjFihM6ePatNmzapoKBAK1eu1NSpU80xDh06pIcfflj33XefduzYoWeffVaTJk3SypUrzZoVK1YoKytLzz33nHbs2KH77rtPDz30kA4fPuzvywYAAB2QzTAMozU/4OTJk4qIiFBJSYnuv/9+eTwe3XrrrXrzzTeVmpoqSTp27JiioqK0evVqpaSkaM2aNRo5cqSOHDkil8slSSooKFB6erqqq6sVGhqqadOmadWqVdq7d6/5WZmZmdq5c6dKS0slSQkJCbrnnnu0ePFis2bAgAEaM2aM8vLyrjp3r9crh8Mhj8ej0NBQf96WmxIdIABAW6ucM8LvY7bk93er7xHyeDySpB49ekiSysvLVV9fr+TkZLPG5XIpNjZWmzdvliSVlpYqNjbWDEGSlJKSotraWpWXl5s1l47RWLN9+3bV19errq5O5eXlzWqSk5PNz2mqtrZWXq/X5wUAADqvVg1ChmEoOztb9957r2JjYyVJVVVVCgoKUlhYmE+t0+lUVVWVWeN0On3Oh4WFKSgo6Io1TqdT58+f16lTp3Tq1Ck1NDRctqZxjKby8vLkcDjMV1RU1PVfPAAAuOm16p/Y+OUvf6m//OUv2rRp01VrDcOQzWYzf77039da07jKZ7PZfP59pTEulZOTo+zsbPNnr9fbqcMQS2EAAKtrtY7Qk08+qVWrVunPf/6zvvnNb5rHIyMjVVdXp5qaGp/66upqs3sTGRnZrGtTU1Oj+vr6K9ZUV1crMDBQ4eHh6tmzpwICAi5b07RL1Mhutys0NNTnBQAAOi+/ByHDMPTLX/5Sf/jDH/Thhx8qOjra53xcXJy6dOmi4uJi89jx48e1e/duDRo0SJKUmJio3bt36/jx42ZNUVGR7Ha74uLizJpLx2isiY+PV5cuXRQUFKS4uLhmNcXFxebnAAAAa/P70tjEiRP19ttv649//KO6d+9udmQcDodCQkLkcDj0+OOPa+rUqQoPD1ePHj301FNP6a677tKDDz4o6eKG5piYGLndbr388sv64osv9NRTTykjI8Ps0mRmZmrhwoXKzs5WRkaGSktLtXTpUi1fvtycS3Z2ttxut+Lj45WYmKglS5bo8OHDyszM9PdlAwCADsjvQajxUfUhQ4b4HP+v//ovpaenS5J+85vfKDAwUGPHjtW5c+f0wAMPaNmyZQoICJAkBQQE6P3339eECRM0ePBghYSEKC0tTfPmzTPHi46O1urVqzVlyhS9+uqrcrlc+u1vf6sf/ehHZk1qaqr+/ve/a/bs2Tp+/LhiY2O1evVq3X777f6+bAAA0AG1+vcIdWSd6XuE2BgNALgZdfrvEQIAALhZEYQAAIBlEYQAAIBlEYQAAIBlteo3S6P9sDkaAICroyMEAAAsiyAEAAAsiyAEAAAsiyAEAAAsi83SnQAbowEAuD50hAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGXx1FgHxFNiAAD4Bx0hAABgWQQhAABgWQQhAABgWQQhAABgWWyWvsmxMRoAgNZDRwgAAFgWQQgAAFgWQQgAAFgWQQgAAFgWQQgAAFgWT43dZHhKDACAtkNHCAAAWBZBCAAAWBZBCAAAWJYlgtCiRYsUHR2t4OBgxcXFaePGje09JQAAcBPo9JulV6xYoaysLC1atEiDBw/W66+/roceekiffPKJbrvttnadGxujAQBoX52+IzR//nw9/vjj+sUvfqEBAwbolVdeUVRUlBYvXtzeUwMAAO2sU3eE6urqVF5erunTp/scT05O1ubNm5vV19bWqra21vzZ4/FIkrxeb6vM70LtV60yLgAAHUVr/I5tHNMwjKvWduogdOrUKTU0NMjpdPocdzqdqqqqalafl5enWbNmNTseFRXVanMEAMDKHK+03tinT5+Ww+G4Yk2nDkKNbDabz8+GYTQ7Jkk5OTnKzs42f75w4YK++OILhYeHX7b+Rni9XkVFRenIkSMKDQ3169j4f9zntsF9bjvc67bBfW4brXWfDcPQ6dOn5XK5rlrbqYNQz549FRAQ0Kz7U11d3axLJEl2u112u93n2C233NKqcwwNDeV/ydoA97ltcJ/bDve6bXCf20Zr3OerdYIaderN0kFBQYqLi1NxcbHP8eLiYg0aNKidZgUAAG4WnbojJEnZ2dlyu92Kj49XYmKilixZosOHDyszM7O9pwYAANpZwMyZM2e29yRaU2xsrMLDw5Wbm6t58+bp3LlzevPNN3X33Xe399QUEBCgIUOGKDCw0+fRdsV9bhvc57bDvW4b3Oe20d732WZcy7NlAAAAnVCn3iMEAABwJQQhAABgWQQhAABgWQQhAABgWQShVrRo0SJFR0crODhYcXFx2rhx4xXrV65cqZiYGNntdsXExKiwsLCNZtqxteQ+v/HGG7rvvvsUFhamsLAwPfjgg9q6dWsbzrbjaul/z40KCgpks9k0ZsyYVp5h59DS+/zll19q4sSJ6tWrl4KDgzVgwACtXr26jWbbsbX0Xr/yyivq37+/QkJCFBUVpSlTpugf//hHG82249mwYYNGjRoll8slm82md99996rvKSkpUVxcnIKDg9W3b1+99tprrT9RA62ioKDA6NKli/HGG28Yn3zyiTF58mSjW7duxueff37Z+s2bNxsBAQFGbm6usXfvXiM3N9cIDAw0ysrK2njmHUtL73NaWprx6quvGjt27DD27t1r/PznPzccDodx9OjRNp55x9LS+9yosrLS6N27t3HfffcZjzzySBvNtuNq6X2ura014uPjjYcfftjYtGmTUVlZaWzcuNGoqKho45l3PC2917///e8Nu91uvPXWW8ahQ4eMDz74wOjVq5eRlZXVxjPvOFavXm0899xzxsqVKw1JRmFh4RXrDx48aHTt2tWYPHmy8cknnxhvvPGG0aVLF+Odd95p1XkShFrJD37wAyMzM9Pn2J133mlMnz79svVjx441hg8f7nMsJSXFeOyxx1ptjp1BS+9zU+fPnze6d+9u/O53v2uN6XUa13Ofz58/bwwePNj4j//4D2PcuHEEoWvQ0vu8ePFio2/fvkZdXV1bTK9Taem9njhxovHP//zPPseys7ONe++9t9Xm2JlcSxB65plnjDvvvNPn2Pjx442BAwe25tQMlsZaQV1dncrLy5WcnOxzPDk5WZs3b77se0pLS5vVp6SkfG09ru8+N/XVV1+pvr5ePXr0aI0pdgrXe59nz56tW2+9VY8//nhrT7FTuJ77vGrVKiUmJmrixIlyOp2KjY1Vbm6uGhoa2mLKHdb13Ot7771X5eXl5lL6wYMHtXr1ao0YMaLV52sVX/d7cPv27aqvr2+1z+XrMlvBqVOn1NDQ0OwPuzqdzmZ/ALZRVVVVi+pxffe5qenTp6t379568MEHW2OKncL13OePPvpIS5cuVUVFRVtMsVO4nvt88OBBffjhh/rJT36i1atX69NPP9XEiRN1/vx5vfDCC20x7Q7peu71Y489ppMnT+ree++VYRg6f/68/u3f/k3Tp09viylbwtf9Hjx//rxOnTqlXr16tcrnEoRakc1m8/nZMIxmx26kHhdd732bO3euli9frvXr1ys4OLi1ptdpXOt9Pn36tH7605/qjTfeUM+ePdtqep1GS/57vnDhgiIiIrRkyRIFBAQoLi5Ox44d08svv0wQugYtudfr16/XSy+9pEWLFikhIUGfffaZJk+erF69emnGjBltMV1LuNz/TC533J8IQq2gZ8+eCggIaPb/WVRXVzdLu40iIyNbVI/ru8+N5s2bp9zcXK1bt07f+c53WnOaHV5L7/Nf//pXVVZWatSoUeaxCxcuSJICAwO1f/9+9evXr3Un3QFdz3/PvXr1UpcuXRQQEGAeGzBggKqqqlRXV6egoKBWnXNHdT33esaMGXK73frFL34hSbrrrrt09uxZPfHEE3ruuef0jW+w0+RGfd3vwcDAQIWHh7fa5/I/uVYQFBSkuLg4FRcX+xwvLi7WoEGDLvuexMTEZvVFRUVfW4/ru8+S9PLLL+vXv/611q5dq/j4+NaeZofX0vt85513ateuXaqoqDBfo0eP1tChQ1VRUaGoqKi2mnqHcj3/PQ8ePFifffaZGTQl6cCBA+rVqxch6Aqu515/9dVXzcJOQECAjIsPHbXaXK3k634PxsfHq0uXLq33wa26FdvCGh/NXLp0qfHJJ58YWVlZRrdu3YzKykrDMAzD7Xb7PJ3w0UcfGQEBAcacOXOMvXv3GnPmzOHx+WvQ0vucn59vBAUFGe+8845x/Phx83X69On2uoQOoaX3uSmeGrs2Lb3Phw8fNv7pn/7J+OUvf2ns37/f+NOf/mREREQYL774YntdQofR0nv9q1/9yujevbuxfPly4+DBg0ZRUZHRr18/Y+zYse11CTe906dPGzt27DB27NhhSDLmz59v7Nixw/yKgunTpxtut9usb3x8fsqUKcYnn3xiLF26lMfnO7pXX33VuP32242goCDjnnvuMUpKSsxzSUlJxrhx43zq/+d//sfo37+/0aVLF+POO+80Vq5c2cYz7phacp9vv/12Q1Kz169+9au2n3gH09L/ni9FELp2Lb3PmzdvNhISEgy73W707dvXeOmll4zz58+38aw7ppbc6/r6emPmzJlGv379jODgYCMqKsqYMGGCUVNT0w4z7xj+/Oc/X/b/3jbe13HjxhlJSUk+71m/fr3xve99zwgKCjL69OljLF68uNXnaTMMenoAAMCa2CMEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAs6/8AZHmkvadT2vcAAAAASUVORK5CYII=",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(df_test.last, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So - is the `rand()` function broken for the last generated random number in each sequence or something else has made the distribution stop being uniform?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
